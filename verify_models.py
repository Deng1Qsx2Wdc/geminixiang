"""
éªŒè¯æ¨¡å‹åˆ—è¡¨è„šæœ¬

ç”¨äºéªŒè¯ API è¿”å›çš„æ¨¡å‹åˆ—è¡¨æ˜¯å¦ä¸ configs/models.json ä¸­çš„æ¨¡å‹ä¸€è‡´
"""

import requests
import json
import os
from pathlib import Path

# é…ç½®
API_BASE_URL = "http://localhost:8000"
API_KEY = "sk-gemini"
MODELS_FILE = os.path.join(os.path.dirname(__file__), "configs", "models.json")

def load_models_from_file():
    """ä» models.json æ–‡ä»¶åŠ è½½æ¨¡å‹åˆ—è¡¨"""
    models_from_file = []
    if os.path.exists(MODELS_FILE):
        try:
            with open(MODELS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                for model in data.get("models", []):
                    model_name = model.get("name", "")
                    # å»æ‰ "models/" å‰ç¼€
                    if model_name.startswith("models/"):
                        model_name = model_name[7:]
                    models_from_file.append({
                        "id": model_name,
                        "displayName": model.get("displayName", ""),
                        "version": model.get("version", ""),
                        "thinking": model.get("thinking", False)
                    })
        except Exception as e:
            print(f"âŒ è¯»å– models.json å¤±è´¥: {e}")
            return []
    return models_from_file

def get_models_from_api(format_type="openai"):
    """ä» API è·å–æ¨¡å‹åˆ—è¡¨"""
    try:
        if format_type == "openai":
            url = f"{API_BASE_URL}/v1/models"
        else:
            url = f"{API_BASE_URL}/v1beta/models"
        
        response = requests.get(
            url,
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json"
            },
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            if format_type == "openai":
                return [{"id": m.get("id", ""), "displayName": "", "version": "", "thinking": False} 
                       for m in data.get("data", [])]
            else:
                return [{"id": m.get("name", "").replace("models/", ""), 
                        "displayName": m.get("displayName", ""),
                        "version": m.get("version", ""),
                        "thinking": m.get("thinking", False)} 
                       for m in data.get("models", [])]
        else:
            print(f"âŒ API è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
            print(f"å“åº”: {response.text}")
            return []
    except Exception as e:
        print(f"âŒ è·å– API æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []

def compare_models(file_models, api_models, format_name, check_thinking=True):
    """å¯¹æ¯”æ¨¡å‹åˆ—è¡¨
    
    Args:
        file_models: æ–‡ä»¶ä¸­çš„æ¨¡å‹åˆ—è¡¨
        api_models: API è¿”å›çš„æ¨¡å‹åˆ—è¡¨
        format_name: æ ¼å¼åç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        check_thinking: æ˜¯å¦æ£€æŸ¥æ€è€ƒæ¨¡å¼ï¼ˆOpenAI æ ¼å¼ä¸åŒ…å«æ­¤å­—æ®µï¼‰
    """
    file_model_ids = {m["id"] for m in file_models}
    api_model_ids = {m["id"] for m in api_models}
    
    # åªåœ¨æ–‡ä»¶ä¸­å­˜åœ¨çš„æ¨¡å‹
    only_in_file = file_model_ids - api_model_ids
    # åªåœ¨ API ä¸­å­˜åœ¨çš„æ¨¡å‹
    only_in_api = api_model_ids - file_model_ids
    # ä¸¤è€…éƒ½å­˜åœ¨çš„æ¨¡å‹
    in_both = file_model_ids & api_model_ids
    
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ {format_name} æ ¼å¼æ¨¡å‹å¯¹æ¯”")
    print(f"{'='*60}")
    
    if not check_thinking:
        print(f"\nğŸ’¡ æ³¨æ„: {format_name} æ ¼å¼ä¸åŒ…å«æ€è€ƒæ¨¡å¼å­—æ®µï¼Œå°†è·³è¿‡è¯¥å­—æ®µçš„å¯¹æ¯”")
    
    print(f"\nâœ… ä¸¤è€…éƒ½å­˜åœ¨çš„æ¨¡å‹ ({len(in_both)} ä¸ª):")
    if in_both:
        for model_id in sorted(in_both):
            file_model = next((m for m in file_models if m["id"] == model_id), None)
            api_model = next((m for m in api_models if m["id"] == model_id), None)
            if file_model and api_model:
                # æ£€æŸ¥è¯¦ç»†ä¿¡æ¯æ˜¯å¦ä¸€è‡´
                details_match = []
                if file_model.get("displayName") and api_model.get("displayName"):
                    if file_model["displayName"] != api_model["displayName"]:
                        details_match.append(f"æ˜¾ç¤ºåç§°ä¸ä¸€è‡´: æ–‡ä»¶={file_model['displayName']}, API={api_model['displayName']}")
                if file_model.get("version") and api_model.get("version"):
                    if file_model["version"] != api_model["version"]:
                        details_match.append(f"ç‰ˆæœ¬ä¸ä¸€è‡´: æ–‡ä»¶={file_model['version']}, API={api_model['version']}")
                # åªæœ‰ Gemini åŸç”Ÿæ ¼å¼æ‰æ£€æŸ¥æ€è€ƒæ¨¡å¼
                if check_thinking and file_model.get("thinking") != api_model.get("thinking"):
                    details_match.append(f"æ€è€ƒæ¨¡å¼ä¸ä¸€è‡´: æ–‡ä»¶={file_model['thinking']}, API={api_model['thinking']}")
                
                if details_match:
                    print(f"  âš ï¸  {model_id}")
                    for detail in details_match:
                        print(f"     - {detail}")
                else:
                    print(f"  âœ… {model_id}")
    else:
        print("  (æ— )")
    
    if only_in_file:
        print(f"\nâš ï¸  åªåœ¨æ–‡ä»¶ä¸­å­˜åœ¨çš„æ¨¡å‹ ({len(only_in_file)} ä¸ª):")
        for model_id in sorted(only_in_file):
            file_model = next((m for m in file_models if m["id"] == model_id), None)
            display_name = file_model.get("displayName", "") if file_model else ""
            print(f"  - {model_id}" + (f" ({display_name})" if display_name else ""))
    
    if only_in_api:
        print(f"\nâš ï¸  åªåœ¨ API ä¸­å­˜åœ¨çš„æ¨¡å‹ ({len(only_in_api)} ä¸ª):")
        for model_id in sorted(only_in_api):
            api_model = next((m for m in api_models if m["id"] == model_id), None)
            display_name = api_model.get("displayName", "") if api_model else ""
            print(f"  - {model_id}" + (f" ({display_name})" if display_name else ""))
    
    # æ€»ç»“
    print(f"\nğŸ“Š å¯¹æ¯”ç»“æœ:")
    print(f"  - æ–‡ä»¶ä¸­çš„æ¨¡å‹æ•°: {len(file_models)}")
    print(f"  - API ä¸­çš„æ¨¡å‹æ•°: {len(api_models)}")
    print(f"  - ä¸¤è€…éƒ½å­˜åœ¨çš„: {len(in_both)}")
    print(f"  - åªåœ¨æ–‡ä»¶ä¸­çš„: {len(only_in_file)}")
    print(f"  - åªåœ¨ API ä¸­çš„: {len(only_in_api)}")
    
    if not only_in_file and not only_in_api:
        print(f"\nâœ… æ¨¡å‹åˆ—è¡¨å®Œå…¨ä¸€è‡´ï¼")
        return True
    else:
        print(f"\nâš ï¸  æ¨¡å‹åˆ—è¡¨å­˜åœ¨å·®å¼‚ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°ä¿¡æ¯")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("æ¨¡å‹åˆ—è¡¨éªŒè¯å·¥å…·")
    print("="*60)
    print(f"\nAPI åœ°å€: {API_BASE_URL}")
    print(f"æ¨¡å‹æ–‡ä»¶: {MODELS_FILE}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(MODELS_FILE):
        print(f"\nâŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODELS_FILE}")
        return
    
    # ä»æ–‡ä»¶åŠ è½½æ¨¡å‹
    print(f"\nğŸ“– ä»æ–‡ä»¶åŠ è½½æ¨¡å‹åˆ—è¡¨...")
    file_models = load_models_from_file()
    if not file_models:
        print("âŒ æ— æ³•ä»æ–‡ä»¶åŠ è½½æ¨¡å‹åˆ—è¡¨")
        return
    
    print(f"âœ… ä»æ–‡ä»¶åŠ è½½äº† {len(file_models)} ä¸ªæ¨¡å‹")
    
    # ä» API è·å–æ¨¡å‹ï¼ˆOpenAI æ ¼å¼ï¼‰
    print(f"\nğŸŒ ä» API è·å–æ¨¡å‹åˆ—è¡¨ (OpenAI æ ¼å¼)...")
    openai_models = get_models_from_api("openai")
    if not openai_models:
        print("âŒ æ— æ³•ä» API è·å–æ¨¡å‹åˆ—è¡¨")
        return
    
    print(f"âœ… ä» API è·å–äº† {len(openai_models)} ä¸ªæ¨¡å‹")
    
    # ä» API è·å–æ¨¡å‹ï¼ˆGemini åŸç”Ÿæ ¼å¼ï¼‰
    print(f"\nğŸŒ ä» API è·å–æ¨¡å‹åˆ—è¡¨ (Gemini åŸç”Ÿæ ¼å¼)...")
    gemini_models = get_models_from_api("gemini")
    if not gemini_models:
        print("âš ï¸  æ— æ³•ä» API è·å– Gemini æ ¼å¼æ¨¡å‹åˆ—è¡¨ï¼ˆå¯èƒ½ä¸æ”¯æŒï¼‰")
    else:
        print(f"âœ… ä» API è·å–äº† {len(gemini_models)} ä¸ªæ¨¡å‹")
    
    # å¯¹æ¯”æ¨¡å‹
    print(f"\n{'='*60}")
    print("å¼€å§‹å¯¹æ¯”æ¨¡å‹åˆ—è¡¨...")
    print(f"{'='*60}")
    
    # å¯¹æ¯” OpenAI æ ¼å¼ï¼ˆä¸æ£€æŸ¥æ€è€ƒæ¨¡å¼ï¼Œå› ä¸º OpenAI æ ¼å¼ä¸åŒ…å«æ­¤å­—æ®µï¼‰
    openai_match = compare_models(file_models, openai_models, "OpenAI", check_thinking=False)
    
    # å¯¹æ¯” Gemini åŸç”Ÿæ ¼å¼ï¼ˆå¦‚æœæœ‰ï¼Œæ£€æŸ¥æ€è€ƒæ¨¡å¼ï¼‰
    if gemini_models:
        print()
        gemini_match = compare_models(file_models, gemini_models, "Gemini åŸç”Ÿ", check_thinking=True)
    
    # æ˜¾ç¤ºæ–‡ä»¶ä¸­çš„æ¨¡å‹è¯¦æƒ…
    print(f"\n{'='*60}")
    print("ğŸ“‹ æ–‡ä»¶ä¸­çš„æ¨¡å‹è¯¦æƒ…")
    print(f"{'='*60}")
    for model in sorted(file_models, key=lambda x: x["id"]):
        thinking_str = "âœ…" if model.get("thinking") else "âŒ"
        print(f"  - {model['id']}")
        if model.get("displayName"):
            print(f"    æ˜¾ç¤ºåç§°: {model['displayName']}")
        if model.get("version"):
            print(f"    ç‰ˆæœ¬: {model['version']}")
        print(f"    æ€è€ƒæ¨¡å¼: {thinking_str}")
    
    print(f"\n{'='*60}")
    print("éªŒè¯å®Œæˆï¼")
    print(f"{'='*60}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

